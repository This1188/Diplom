
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from text_analysis.llm_analyzer import create_llm_analyzer, Document
from datetime import datetime

def test_llm_analyzer():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã LLM –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    test_documents = [
        Document(
            id="doc_1",
            date="2024-03-01",
            theme="–•–æ–∫–∫–µ–π–Ω—ã–π –º–∞—Ç—á",
            text="–í—á–µ—Ä–∞ —Å–æ—Å—Ç–æ—è–ª—Å—è –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π –º–∞—Ç—á –º–µ–∂–¥—É –∫–æ–º–∞–Ω–¥–∞–º–∏ –°–ø–∞—Ä—Ç–∞–∫ –∏ –¶–°–ö–ê. "
                 "–ò–≥—Ä–∞ –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å —Å–æ —Å—á–µ—Ç–æ–º 3:2 –≤ –ø–æ–ª—å–∑—É –°–ø–∞—Ä—Ç–∞–∫–∞. –õ—É—á—à–∏–º –∏–≥—Ä–æ–∫–æ–º "
                 "–º–∞—Ç—á–∞ –±—ã–ª –ø—Ä–∏–∑–Ω–∞–Ω –≤—Ä–∞—Ç–∞—Ä—å, –æ—Ç—Ä–∞–∑–∏–≤—à–∏–π 35 –±—Ä–æ—Å–∫–æ–≤ –ø–æ –≤–æ—Ä–æ—Ç–∞–º."
        ),
        Document(
            id="doc_2",
            date="2024-03-01",
            theme="–•–æ–∫–∫–µ–π–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è",
            text="–î—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–±–µ–¥–∞ –ê–∫ –ë–∞—Ä—Å–∞ –Ω–∞–¥ –°–ö–ê –≤ –æ–≤–µ—Ä—Ç–∞–π–º–µ. –ö–æ–º–∞–Ω–¥–∞ –∏–∑ –ö–∞–∑–∞–Ω–∏ "
                 "—Å—É–º–µ–ª–∞ –æ—Ç—ã–≥—Ä–∞—Ç—å—Å—è –∑–∞ –¥–≤–µ –º–∏–Ω—É—Ç—ã –¥–æ –∫–æ–Ω—Ü–∞ —Ç—Ä–µ—Ç—å–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ –∏ –ø–æ–±–µ–¥–∏–ª–∞ "
                 "–≤ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è. –•–µ—Ç-—Ç—Ä–∏–∫ –æ—Ñ–æ—Ä–º–∏–ª –∫–∞–ø–∏—Ç–∞–Ω –∫–æ–º–∞–Ω–¥—ã."
        ),
        Document(
            id="doc_3",
            date="2024-03-01",
            theme="–ù–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            text="–ö–æ–º–ø–∞–Ω–∏—è Apple –∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª–∞ –Ω–æ–≤—ã–π iPhone —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–∞–º–µ—Ä–æ–π –∏ "
                 "–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª—É—á–∏–ª–æ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ "
                 "–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π."
        ),
        Document(
            id="doc_4",
            date="2024-03-02",
            theme="–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
            text="–≠–∫—Å–ø–µ—Ä—Ç—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –Ω–æ–≤—É—é —É—è–∑–≤–∏–º–æ—Å—Ç—å –≤ –ø–æ–ø—É–ª—è—Ä–Ω–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º "
                 "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è "
                 "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –∑–∞—â–∏—Ç—ã –¥–∞–Ω–Ω—ã—Ö."
        ),
        Document(
            id="doc_5",
            date="2024-03-03",
            theme="–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä—ã–Ω–∫–∏",
            text="–§–æ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –ø–æ–∫–∞–∑–∞–ª–∏ —Ä–æ—Å—Ç –Ω–∞ —Ñ–æ–Ω–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö "
                 "–¥–∞–Ω–Ω—ã—Ö. –ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è "
                 "—ç–∫–æ–Ω–æ–º–∏–∫–∏."
        ),
        Document(
            id="doc_6",
            date="2024-03-04",
            theme="–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã",
            text="–ë–∏—Ç–∫–æ–∏–Ω –¥–æ—Å—Ç–∏–≥ –Ω–æ–≤–æ–≥–æ –º–∞–∫—Å–∏–º—É–º–∞ –±–ª–∞–≥–æ–¥–∞—Ä—è –∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º "
                 "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–º. –≠–∫—Å–ø–µ—Ä—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é—Ç –¥–∞–ª—å–Ω–µ–π—à–∏–π —Ä–æ—Å—Ç —Ä—ã–Ω–∫–∞ "
                 "—Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∞–∫—Ç–∏–≤–æ–≤."
        )
    ]
    
    print("=" * 60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï LLM –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê –¢–ï–ú")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    print("\nüß† –°–æ–∑–¥–∞–Ω–∏–µ LLM –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞...")
    analyzer = create_llm_analyzer(
        provider="ollama",
        model="mistral",  # –∏–ª–∏ "llama2", "llama3"
        ollama_url="http://localhost:11434"
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama...")
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            print("‚úÖ Ollama –¥–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print("‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
    except:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω: ollama serve")
        return
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ {len(test_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    start_time = datetime.now()
    
    result = analyzer.analyze_topics(test_documents, use_cache=True)
    
    elapsed = (datetime.now() - start_time).total_seconds()
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {elapsed:.2f} —Å–µ–∫—É–Ω–¥")
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ç–µ–º: {result['metadata']['topics_discovered']}")
    print(f"üìÑ –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {result['metadata']['total_documents']}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {result['metadata']['model_used']}")
    
    print("\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
    print("=" * 60)
    
    for i, topic in enumerate(result['topics']):
        if topic['document_count'] > 0:
            print(f"\n–¢–µ–º–∞ #{i+1}: {topic['topic_name']}")
            print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {topic.get('category', 'general')}")
            print(f"  –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {topic['document_count']}")
            print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {topic.get('confidence', 0.7):.2f}")
            print(f"  –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(topic['keywords'][:5])}")
            
            if topic.get('description'):
                print(f"  –û–ø–∏—Å–∞–Ω–∏–µ: {topic['description'][:100]}...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–ø—Ä–∞–≤–∫–∏
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ì–ï–ù–ï–†–ê–¶–ò–ò –°–ü–†–ê–í–ö–ò")
    print("=" * 60)
    
    if result['topics']:
        first_topic = result['topics'][0]
        
        print(f"\nüìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ø—Ä–∞–≤–∫–∏ –¥–ª—è —Ç–µ–º—ã: {first_topic['topic_name']}")
        
        summary = analyzer.generate_summary(
            topic=first_topic,
            documents=test_documents,
            start_date="2024-03-01",
            end_date="2024-03-10"
        )
        
        print("\nüìÑ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–ê–Ø –°–ü–†–ê–í–ö–ê:")
        print("=" * 60)
        print(summary[:500] + "..." if len(summary) > 500 else summary)
        print("=" * 60)
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    test_llm_analyzer()