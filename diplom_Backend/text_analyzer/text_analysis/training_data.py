import json
import numpy as np
from sklearn.model_selection import train_test_split
from improved_analyzer import HybridTopicAnalyzer, EnhancedTextProcessor

class TopicTrainingData:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    
    def __init__(self, data_file='training_data.json'):
        self.data_file = data_file
        self.processor = EnhancedTextProcessor()
        self.load_data()
    
    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.data)} —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        except FileNotFoundError:
            self.data = []
            print("–§–∞–π–ª —Å –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π")
    
    def save_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        with open(self.data_file, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self.data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    def add_training_example(self, text, true_topics, source='manual'):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            text: —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            true_topics: —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–∏–Ω–Ω—ã—Ö —Ç–µ–º (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ)
            source: –∏—Å—Ç–æ—á–Ω–∏–∫ —Ä–∞–∑–º–µ—Ç–∫–∏
        """
        example = {
            'text': text,
            'true_topics': true_topics,
            'processed_text': self.processor.process_document(text),
            'source': source,
            'theme_guess': self.processor.guess_theme(text)
        }
        self.data.append(example)
        return example
    
    def create_synthetic_data(self, n_examples=100):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ {n_examples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤...")
        
        templates = {
            '—Å–ø–æ—Ä—Ç': [
                "–í –º–∞—Ç—á–µ –ø–æ {–≤–∏–¥_—Å–ø–æ—Ä—Ç–∞} –∫–æ–º–∞–Ω–¥–∞ {–∫–æ–º–∞–Ω–¥–∞1} –æ–¥–µ—Ä–∂–∞–ª–∞ –ø–æ–±–µ–¥—É –Ω–∞–¥ {–∫–æ–º–∞–Ω–¥–∞2} —Å–æ —Å—á–µ—Ç–æ–º {—Å—á–µ—Ç}.",
                "–ò–≥—Ä–æ–∫ {–∏–≥—Ä–æ–∫} –ø–æ–ª—É—á–∏–ª —Ç—Ä–∞–≤–º—É {—Ç–∏–ø_—Ç—Ä–∞–≤–º—ã} –∏ –≤—ã–±—ã–ª –Ω–∞ {—Å—Ä–æ–∫} –Ω–µ–¥–µ–ª—å.",
                "–¢—Ä–µ–Ω–µ—Ä {–∫–æ–º–∞–Ω–¥–∞} –∑–∞—è–≤–∏–ª –æ {–¥–µ–π—Å—Ç–≤–∏–µ} –≤ —Å–ª–µ–¥—É—é—â–µ–º –º–∞—Ç—á–µ –ø—Ä–æ—Ç–∏–≤ {—Å–æ–ø–µ—Ä–Ω–∏–∫}."
            ],
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': [
                "–ö–æ–º–ø–∞–Ω–∏—è {–∫–æ–º–ø–∞–Ω–∏—è} –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–π {–ø—Ä–æ–¥—É–∫—Ç} —Å {—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞}.",
                "–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≤—ã–ø—É—Å—Ç–∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è {–ø—Ä–æ–≥—Ä–∞–º–º–∞} –≤–µ—Ä—Å–∏–∏ {–≤–µ—Ä—Å–∏—è}.",
                "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Å–æ–∑–¥–∞–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è {–∑–∞–¥–∞—á–∞} —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {—Ç–æ—á–Ω–æ—Å—Ç—å}%."
            ],
            '—Ñ–∏–Ω–∞–Ω—Å—ã': [
                "–ê–∫—Ü–∏–∏ {–∫–æ–º–ø–∞–Ω–∏—è} –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ {–ø—Ä–æ—Ü–µ–Ω—Ç}% –ø–æ—Å–ª–µ {–Ω–æ–≤–æ—Å—Ç—å}.",
                "–ë–∞–Ω–∫ {–±–∞–Ω–∫} —Å–Ω–∏–∑–∏–ª —Å—Ç–∞–≤–∫—É –ø–æ {–ø—Ä–æ–¥—É–∫—Ç} –¥–æ {—Å—Ç–∞–≤–∫–∞}%.",
                "–≠–∫—Å–ø–µ—Ä—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é—Ç {–∏–∑–º–µ–Ω–µ–Ω–∏–µ} {–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å} –Ω–∞ {–∑–Ω–∞—á–µ–Ω–∏–µ}."
            ]
        }
        
        parameters = {
            '–≤–∏–¥_—Å–ø–æ—Ä—Ç–∞': ['—Ö–æ–∫–∫–µ—é', '—Ñ—É—Ç–±–æ–ª—É', '–±–∞—Å–∫–µ—Ç–±–æ–ª—É', '—Ç–µ–Ω–Ω–∏—Å—É'],
            '–∫–æ–º–∞–Ω–¥–∞1': ['–°–ø–∞—Ä—Ç–∞–∫', '–¶–°–ö–ê', '–î–∏–Ω–∞–º–æ', '–ó–µ–Ω–∏—Ç', '–õ–æ–∫–æ–º–æ—Ç–∏–≤'],
            '–∫–æ–º–∞–Ω–¥–∞2': ['–ê–∫ –ë–∞—Ä—Å', '–°–ö–ê', '–°–∞–ª–∞–≤–∞—Ç –Æ–ª–∞–µ–≤', '–¢—Ä–∞–∫—Ç–æ—Ä'],
            '—Å—á–µ—Ç': ['3:2', '2:1', '4:0', '1:0'],
            '–∏–≥—Ä–æ–∫': ['–ò–≤–∞–Ω–æ–≤', '–ü–µ—Ç—Ä–æ–≤', '–°–∏–¥–æ—Ä–æ–≤', '–ö—É–∑–Ω–µ—Ü–æ–≤'],
            '—Ç–∏–ø_—Ç—Ä–∞–≤–º—ã': ['—Ä–∞—Å—Ç—è–∂–µ–Ω–∏—è —Å–≤—è–∑–æ–∫', '–ø–µ—Ä–µ–ª–æ–º–∞', '—É—à–∏–±–∞', '—Å–æ—Ç—Ä—è—Å–µ–Ω–∏—è'],
            '—Å—Ä–æ–∫': ['2', '4', '6', '8'],
            '–∫–æ–º–ø–∞–Ω–∏—è': ['Apple', 'Samsung', 'Google', 'Microsoft', 'Tesla'],
            '–ø—Ä–æ–¥—É–∫—Ç': ['—Å–º–∞—Ä—Ç—Ñ–æ–Ω', '–Ω–æ—É—Ç–±—É–∫', '–ø–ª–∞–Ω—à–µ—Ç', '—É–º–Ω—ã–µ —á–∞—Å—ã'],
            '—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': ['—É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–∞–º–µ—Ä–æ–π', '–Ω–æ–≤—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º', '–±–æ–ª—å—à–∏–º —ç–∫—Ä–∞–Ω–æ–º'],
            '–ø—Ä–æ–≥—Ä–∞–º–º–∞': ['–æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', '–∏–≥—Ä—ã'],
            '–≤–µ—Ä—Å–∏—è': ['15.0', '2.1', '2024', 'Pro'],
            '–∑–∞–¥–∞—á–∞': ['—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', '–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞', '–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è'],
            '—Ç–æ—á–Ω–æ—Å—Ç—å': ['95', '98', '99', '99.5'],
            '–ø—Ä–æ—Ü–µ–Ω—Ç': ['5', '10', '15', '20'],
            '–Ω–æ–≤–æ—Å—Ç—å': ['–æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–∏–±—ã–ª–∏', '–∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–∞', '–ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞'],
            '–±–∞–Ω–∫': ['–°–±–µ—Ä–±–∞–Ω–∫', '–í–¢–ë', '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫', '–¢–∏–Ω—å–∫–æ—Ñ—Ñ'],
            '—Å—Ç–∞–≤–∫–∞': ['5.5', '6.0', '7.2', '8.5'],
            '–∏–∑–º–µ–Ω–µ–Ω–∏–µ': ['—Ä–æ—Å—Ç', '—Å–Ω–∏–∂–µ–Ω–∏–µ', '—Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—é'],
            '–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å': ['–∏–Ω—Ñ–ª—è—Ü–∏–∏', '–í–í–ü', '–∫—É—Ä—Å–∞ –≤–∞–ª—é—Ç—ã'],
            '–∑–Ω–∞—á–µ–Ω–∏–µ': ['3%', '5%', '2.5%', '4.7%']
        }
        
        for _ in range(n_examples):
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é —Ç–µ–º—É
            theme = np.random.choice(list(templates.keys()))
            template = np.random.choice(templates[theme])
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º —à–∞–±–ª–æ–Ω
            text = template
            for param in parameters:
                if f"{{{param}}}" in text:
                    value = np.random.choice(parameters[param])
                    text = text.replace(f"{{{param}}}", value)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –¥–∞–Ω–Ω—ã–µ
            self.add_training_example(text, [theme], source='synthetic')
        
        self.save_data()
        print(f"–°–æ–∑–¥–∞–Ω–æ {n_examples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    def train_classifier(self, analyzer):
        """
        –î–æ–æ–±—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        """
        if len(self.data) < 10:
            print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return
        
        print(f"–î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(self.data)} —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ –º–µ—Ç–∫–∏
        texts = [item['text'] for item in self.data]
        true_topics = [item['true_topics'] for item in self.data]
        
        # –û–±—É—á–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        results = analyzer.ensemble_analysis(texts)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        self.evaluate_results(results, true_topics)
        
        return results
    
    def evaluate_results(self, results, true_topics):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        print("\n" + "=" * 60)
        print("–û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
        print("=" * 60)
        
        consensus_stats = results['consensus']['topic_statistics']
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏
        theme_mapping = {}
        for topic in consensus_stats:
            if topic['document_count'] > 0:
                # –î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —ç—Ç–æ–π —Ç–µ–º—ã —Å–º–æ—Ç—Ä–∏–º –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                doc_indices = topic['document_indices']
                if doc_indices:
                    true_themes_for_topic = []
                    for idx in doc_indices:
                        if idx < len(true_topics):
                            true_themes_for_topic.extend(true_topics[idx])
                    
                    # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –∏—Å—Ç–∏–Ω–Ω—É—é —Ç–µ–º—É
                    if true_themes_for_topic:
                        from collections import Counter
                        most_common = Counter(true_themes_for_topic).most_common(1)
                        if most_common:
                            true_theme = most_common[0][0]
                            theme_mapping[topic['topic_id']] = true_theme
                            print(f"–¢–µ–º–∞ #{topic['topic_id']} -> '{true_theme}' "
                                  f"(—Ç–æ—á–Ω–æ—Å—Ç—å: {most_common[0][1]/len(true_themes_for_topic):.1%})")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —Ç–æ—á–Ω–æ—Å—Ç—å
        correct = 0
        total = 0
        
        for idx, assignment in enumerate(results['consensus']['assignments']):
            if idx < len(true_topics):
                predicted_topic = assignment['dominant_topic']
                predicted_theme = theme_mapping.get(predicted_topic, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                
                if predicted_theme in true_topics[idx]:
                    correct += 1
                total += 1
        
        if total > 0:
            accuracy = correct / total
            print(f"\nüìä –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%} ({correct}/{total})")
            
            if accuracy < 0.7:
                print("‚ö†Ô∏è  –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
            elif accuracy < 0.85:
                print("‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∞—è")
            else:
                print("üéØ –û—Ç–ª–∏—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å!")
        
        return accuracy


def create_predefined_training_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    training_data = TopicTrainingData()
    
    # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ö–æ–∫–∫–µ—è
    hockey_examples = [
        ("–í—á–µ—Ä–∞ —Å–æ—Å—Ç–æ—è–ª—Å—è –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π –º–∞—Ç—á –º–µ–∂–¥—É –∫–æ–º–∞–Ω–¥–∞–º–∏ –°–ø–∞—Ä—Ç–∞–∫ –∏ –¶–°–ö–ê. "
         "–ò–≥—Ä–∞ –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å —Å–æ —Å—á–µ—Ç–æ–º 3:2 –≤ –ø–æ–ª—å–∑—É –°–ø–∞—Ä—Ç–∞–∫–∞.", ['—Å–ø–æ—Ä—Ç']),
        
        ("–î—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–±–µ–¥–∞ –ê–∫ –ë–∞—Ä—Å–∞ –Ω–∞–¥ –°–ö–ê –≤ –æ–≤–µ—Ä—Ç–∞–π–º–µ. "
         "–ö–æ–º–∞–Ω–¥–∞ –∏–∑ –ö–∞–∑–∞–Ω–∏ —Å—É–º–µ–ª–∞ –æ—Ç—ã–≥—Ä–∞—Ç—å—Å—è –∑–∞ –¥–≤–µ –º–∏–Ω—É—Ç—ã –¥–æ –∫–æ–Ω—Ü–∞ —Ç—Ä–µ—Ç—å–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞.", ['—Å–ø–æ—Ä—Ç']),
        
        ("–¢—Ä–∞–≤–º–∞ –∫–ª—é—á–µ–≤–æ–≥–æ –Ω–∞–ø–∞–¥–∞—é—â–µ–≥–æ –î–∏–Ω–∞–º–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –∏—Å—Ö–æ–¥ –ø–ª–µ–π-–æ—Ñ—Ñ. "
         "–í—Ä–∞—á–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É—é—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ –∫–æ–ª–µ–Ω–∞.", ['—Å–ø–æ—Ä—Ç']),
        
        ("–ú–æ–ª–æ–¥–æ–π –≤—Ä–∞—Ç–∞—Ä—å –ê–≤—Ç–æ–º–æ–±–∏–ª–∏—Å—Ç–∞ –¥–µ–±—é—Ç–∏—Ä–æ–≤–∞–ª –≤ –ö–•–õ –∏ —Å—Ä–∞–∑—É —Å–¥–µ–ª–∞–ª —à–∞—Ç–∞—É—Ç. "
         "20-–ª–µ—Ç–Ω–∏–π –≥–æ–ª–∫–∏–ø–µ—Ä –æ—Ç—Ä–∞–∑–∏–ª –≤—Å–µ 28 –±—Ä–æ—Å–∫–æ–≤.", ['—Å–ø–æ—Ä—Ç']),
        
        ("–†–µ–∫–æ—Ä–¥ –ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç–∏ –Ω–∞ –º–∞—Ç—á–µ –õ–æ–∫–æ–º–æ—Ç–∏–≤ - –°–∞–ª–∞–≤–∞—Ç –Æ–ª–∞–µ–≤. "
         "–ë–æ–ª–µ–µ 12 —Ç—ã—Å—è—á –∑—Ä–∏—Ç–µ–ª–µ–π —Å—Ç–∞–ª–∏ —Å–≤–∏–¥–µ—Ç–µ–ª—è–º–∏ —Å–µ–º–∏–≥–æ–ª–µ–≤–æ–π –ø–æ–±–µ–¥–Ω–æ–π –∏–≥—Ä—ã.", ['—Å–ø–æ—Ä—Ç'])
    ]
    
    # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
    tech_examples = [
        ("–ö–æ–º–ø–∞–Ω–∏—è Apple –∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª–∞ –Ω–æ–≤—ã–π iPhone —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–∞–º–µ—Ä–æ–π –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º. "
         "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª—É—á–∏–ª–æ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.", ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏']),
        
        ("–≠–∫—Å–ø–µ—Ä—Ç—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –Ω–æ–≤—É—é —É—è–∑–≤–∏–º–æ—Å—Ç—å –≤ –ø–æ–ø—É–ª—è—Ä–Ω–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–∏. "
         "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.", ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏']),
        
        ("–£—á–µ–Ω—ã–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π. "
         "–ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å 95%.", ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏']),
        
        ("Tesla –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Å—Ä–æ–∫–æ–º —Å–ª—É–∂–±—ã. "
         "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–æ–±–µ–≥ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π –Ω–∞ 20%.", ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏']),
        
        ("–ß–∞—Å—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—Å—Ç–∏–ª–∞ —Ä–∞–∫–µ—Ç—É —Å –Ω–∞—É—á–Ω—ã–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º –Ω–∞ –æ—Ä–±–∏—Ç—É. "
         "–ú–∏—Å—Å–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ –∏–∑—É—á–µ–Ω–∏–µ –∫–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π.", ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'])
    ]
    
    # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤
    finance_examples = [
        ("–§–æ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –ø–æ–∫–∞–∑–∞–ª–∏ —Ä–æ—Å—Ç –Ω–∞ —Ñ–æ–Ω–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö. "
         "–ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è —ç–∫–æ–Ω–æ–º–∏–∫–∏.", ['—Ñ–∏–Ω–∞–Ω—Å—ã']),
        
        ("–ë–∏—Ç–∫–æ–∏–Ω –¥–æ—Å—Ç–∏–≥ –Ω–æ–≤–æ–≥–æ –º–∞–∫—Å–∏–º—É–º–∞ –±–ª–∞–≥–æ–¥–∞—Ä—è –∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–º. "
         "–≠–∫—Å–ø–µ—Ä—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é—Ç –¥–∞–ª—å–Ω–µ–π—à–∏–π —Ä–æ—Å—Ç —Ä—ã–Ω–∫–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∞–∫—Ç–∏–≤–æ–≤.", ['—Ñ–∏–Ω–∞–Ω—Å—ã']),
        
        ("–¶–µ–Ω—ã –Ω–∞ –∂–∏–ª—å–µ –≤ –∫—Ä—É–ø–Ω—ã—Ö –≥–æ—Ä–æ–¥–∞—Ö –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Ä–∞—Å—Ç–∏. "
         "–ê–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å–≤—è–∑—ã–≤–∞—é—Ç —ç—Ç–æ —Å –Ω–∏–∑–∫–∏–º–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏.", ['—Ñ–∏–Ω–∞–Ω—Å—ã']),
        
        ("–°—Ç—Ä–∞–Ω—ã –ø–æ–¥–ø–∏—Å–∞–ª–∏ –Ω–æ–≤–æ–µ —Ç–æ—Ä–≥–æ–≤–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–æ —Å—Ç–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç. "
         "–î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç —Å–Ω–∏–∂–µ–Ω–∏–µ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ—à–ª–∏–Ω.", ['—Ñ–∏–Ω–∞–Ω—Å—ã']),
        
        ("–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–ª—è –±–æ—Ä—å–±—ã —Å —Ä–∞—Å—Ç—É—â–µ–π –∏–Ω—Ñ–ª—è—Ü–∏–µ–π. "
         "–≠–∫–æ–Ω–æ–º–∏—Å—Ç—ã –æ–∂–∏–¥–∞—é—Ç –∑–∞–º–µ–¥–ª–µ–Ω–∏—è —Ä–æ—Å—Ç–∞ —Ü–µ–Ω.", ['—Ñ–∏–Ω–∞–Ω—Å—ã'])
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã
    all_examples = hockey_examples + tech_examples + finance_examples
    
    for text, topics in all_examples:
        training_data.add_training_example(text, topics, source='predefined')
    
    # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    training_data.create_synthetic_data(n_examples=50)
    
    training_data.save_data()
    print(f"\n–°–æ–∑–¥–∞–Ω–æ {len(training_data.data)} –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    return training_data


if __name__ == "__main__":
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    training_data = create_predefined_training_data()
    
    # –û–±—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = HybridTopicAnalyzer()
    results = training_data.train_classifier(analyzer)
    
    print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")